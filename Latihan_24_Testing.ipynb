{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latihan 24 - Testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LYc3yUELO8_t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iZGxyDfR-9w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load the data\n",
        "training_file = \"/content/drive/MyDrive/Dataset/German Traffic Sign/train.p\"\n",
        "testing_file = \"/content/drive/MyDrive/Dataset/German Traffic Sign/test.p\"   \n",
        " \n",
        "# Open and load the training file \n",
        "with open(training_file, mode='rb') as f:\n",
        "    train = pickle.load(f)\n",
        " \n",
        "# Open and load the testing file\n",
        "with open(testing_file, mode='rb') as f:\n",
        "    test = pickle.load(f)\n",
        "    \n",
        "print(\"Data loaded\")"
      ],
      "metadata": {
        "id": "Equ1H0-a-pzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## let's create a pandas dataframe to load csv\n",
        "## The content of csv file is ClassId and the SignName\n",
        " \n",
        "sign_name_df = pd.read_csv('/content/drive/MyDrive/Dataset/German Traffic Sign/signnames.csv')\n",
        "SIGN_NAMES = sign_name_df.SignName.values\n",
        "sign_name_df.set_index('ClassId', inplace=True)\n",
        "sign_name_df.head(10)"
      ],
      "metadata": {
        "id": "OzrukUA1_LD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and labels for training data \n",
        "X, y = train['features'], train['labels']\n",
        " \n",
        "# Converting lists into numpy arrays\n",
        "data = np.array(X)\n",
        "labels = np.array(y)\n",
        "print(data.shape, labels.shape)\n",
        " \n",
        "# Define the features and labels for testing data\n",
        "X_test, y_test = test['features'], test['labels']\n",
        " \n",
        "# Converting lists into numpy arrays\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "vn_Q-KXg_Lir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "LcfeEI70_Ljq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_labels = np.unique(y_train).size\n",
        "def hist_data(y_data, title=None, ax=None, **kwargs):\n",
        "    if not ax :\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "    ax.hist(y_data, np.arange(-0.5, n_labels+1.5), stacked=True, **kwargs)\n",
        "    ax.set_xlim(-0.5, n_labels-0.5)\n",
        "    if 'label' in kwargs : ax.legend()\n",
        "    if title : ax.set_title(title)\n",
        "        \n",
        "fig,ax = plt.subplots(1,3, figsize=(20,5))\n",
        "hist_data(y_train, title='Distribusi kelas pada data training', ax=ax[0])\n",
        "hist_data(y_val, title='Distribusi kelas pada data validasi', ax=ax[1], color='black')\n",
        "hist_data(y_test, title='Distribusi kelas pada data test', ax=ax[2], color='grey')"
      ],
      "metadata": {
        "id": "SoFPo3-T_a7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the labels into one hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        " \n",
        "y_train = to_categorical(y_train, 43)\n",
        "y_val = to_categorical(y_val, 43)"
      ],
      "metadata": {
        "id": "GTh8ogTK_lc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.96):\n",
        "      print(\"\\nAkurasi telah mencapai >96%. Stop training!\")\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "0G_CCbRc_6go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "model = Sequential()\n",
        "\n",
        "#Layer Pertama\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "#Layer Kedua\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Fully Connected Layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(43, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3Ui1DR-1_7Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "epochs = 25\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_val, y_val), callbacks=[callbacks])\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "id": "pSShCxh2BiRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting graphs for accuracy \n",
        "plt.figure(0)\n",
        "plt.plot(history.history['accuracy'], label='training accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        " \n",
        "# Plotting graphs for loss\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['loss'], label='training loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gwEl8YLqBu_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing accuracy with the test data\n",
        "from sklearn.metrics import accuracy_score\n",
        " \n",
        "pred=np.argmax(model.predict(X_test), axis=-1)\n",
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "id": "1TTUmOq6B_aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for classification\n",
        "from sklearn.metrics import classification_report\n",
        " \n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "id": "IvSmjo8LCJcz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}